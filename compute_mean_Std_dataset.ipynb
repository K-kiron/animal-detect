{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m1UKVITUr_9Q"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import csv\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import math\n",
        "\n",
        "import torch \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision \n",
        "from torchvision.io import read_image\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "np.random.seed(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzQK38Xvsevn",
        "outputId": "775f4128-e41e-4a5a-e784-aa0eb6fbdca2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constant. Should be the path to the folder named JPEGImages, containing the 33K images in its subfolders.\n",
        "DATA_FOLDER_PATH = '/content/drive/MyDrive/IFT3710/Animals_with_Attributes2/'\n",
        "JPEGIMAGES_FOLDER_PATH = '/content/drive/MyDrive/IFT3710/Animals_with_Attributes2/JPEGImages/'"
      ],
      "metadata": {
        "id": "8D_qVmS_sGos"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_dirs = os.listdir(JPEGIMAGES_FOLDER_PATH)\n",
        "print(labels_dirs)\n",
        "len(labels_dirs) # 50 labels / subdirectories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtRNOwhNsRhC",
        "outputId": "b46594dd-136e-4b0d-87e1-fa370bdd6a68"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['elephant', 'lion', 'deer', 'cow', 'squirrel', 'german+shepherd', 'skunk', 'horse', 'mole', 'walrus', 'weasel', 'mouse', 'buffalo', 'grizzly+bear', 'bat', 'chimpanzee', 'beaver', 'rabbit', 'wolf', 'bobcat', 'seal', 'collie', 'spider+monkey', 'otter', 'rat', 'leopard', 'zebra', 'sheep', 'blue+whale', 'ox', 'chihuahua', 'hamster', 'tiger', 'giraffe', 'polar+bear', 'dolphin', 'fox', 'siamese+cat', 'persian+cat', 'raccoon', 'antelope', 'pig', 'giant+panda', 'killer+whale', 'moose', 'dalmatian', 'humpback+whale', 'gorilla', 'rhinoceros', 'hippopotamus']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_num_images_per_label(img_dir = JPEGIMAGES_FOLDER_PATH): #-> tuple[dict,dict]: \n",
        "    \"\"\" \n",
        "    USEFUL FOR SAMPLING.\n",
        "    Return a dict with keys as the 50 labels, and values being the number of images in each subdirectory corresponding to label\n",
        "    and a second dict with the relative numbers (proportion) for every label compared to the total number of images (useful for sampling)\"\"\"\n",
        "    labels_dirs = os.listdir(img_dir)\n",
        "    num_images_per_label = dict.fromkeys(labels_dirs)\n",
        "    proportions_images_per_label = dict.fromkeys(labels_dirs)\n",
        "    total_num_images = 0\n",
        "\n",
        "    # Update absolute number of images per label\n",
        "    for i, label in enumerate(labels_dirs) : \n",
        "        specific_label_path = os.path.join(img_dir, labels_dirs[i])\n",
        "        num_images_label = len(os.listdir(specific_label_path))\n",
        "        total_num_images += num_images_label\n",
        "        num_images_per_label[label] = num_images_label\n",
        "\n",
        "    # Update relative number of images per label (proportion)\n",
        "    for i, label in enumerate(labels_dirs) : \n",
        "        num_images_label = num_images_per_label[label]\n",
        "        proportion_label = round(num_images_label / total_num_images, 4)\n",
        "        proportions_images_per_label[label] = proportion_label\n",
        "\n",
        "    return num_images_per_label, proportions_images_per_label\n",
        "\n",
        "num_images_per_label, proportions_images_per_label = find_num_images_per_label()\n",
        "print(num_images_per_label)\n",
        "print(proportions_images_per_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3kjEitPsWNi",
        "outputId": "a1902bf8-0db8-4d7f-9474-285522de55b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'elephant': 1038, 'lion': 1019, 'deer': 1344, 'cow': 1338, 'squirrel': 1200, 'german+shepherd': 1033, 'skunk': 188, 'horse': 1645, 'mole': 100, 'walrus': 215, 'weasel': 282, 'mouse': 185, 'buffalo': 904, 'grizzly+bear': 852, 'bat': 383, 'chimpanzee': 728, 'beaver': 193, 'rabbit': 1088, 'wolf': 589, 'bobcat': 630, 'seal': 988, 'collie': 1028, 'spider+monkey': 291, 'otter': 758, 'rat': 310, 'leopard': 720, 'zebra': 1170, 'sheep': 1420, 'blue+whale': 174, 'ox': 728, 'chihuahua': 567, 'hamster': 779, 'tiger': 877, 'giraffe': 1202, 'polar+bear': 868, 'dolphin': 946, 'fox': 664, 'siamese+cat': 500, 'persian+cat': 747, 'raccoon': 512, 'antelope': 1046, 'pig': 713, 'giant+panda': 874, 'killer+whale': 291, 'moose': 704, 'dalmatian': 549, 'humpback+whale': 709, 'gorilla': 872, 'rhinoceros': 696, 'hippopotamus': 684}\n",
            "{'elephant': 0.0278, 'lion': 0.0273, 'deer': 0.036, 'cow': 0.0358, 'squirrel': 0.0321, 'german+shepherd': 0.0277, 'skunk': 0.005, 'horse': 0.0441, 'mole': 0.0027, 'walrus': 0.0058, 'weasel': 0.0076, 'mouse': 0.005, 'buffalo': 0.0242, 'grizzly+bear': 0.0228, 'bat': 0.0103, 'chimpanzee': 0.0195, 'beaver': 0.0052, 'rabbit': 0.0291, 'wolf': 0.0158, 'bobcat': 0.0169, 'seal': 0.0265, 'collie': 0.0275, 'spider+monkey': 0.0078, 'otter': 0.0203, 'rat': 0.0083, 'leopard': 0.0193, 'zebra': 0.0313, 'sheep': 0.038, 'blue+whale': 0.0047, 'ox': 0.0195, 'chihuahua': 0.0152, 'hamster': 0.0209, 'tiger': 0.0235, 'giraffe': 0.0322, 'polar+bear': 0.0232, 'dolphin': 0.0253, 'fox': 0.0178, 'siamese+cat': 0.0134, 'persian+cat': 0.02, 'raccoon': 0.0137, 'antelope': 0.028, 'pig': 0.0191, 'giant+panda': 0.0234, 'killer+whale': 0.0078, 'moose': 0.0189, 'dalmatian': 0.0147, 'humpback+whale': 0.019, 'gorilla': 0.0234, 'rhinoceros': 0.0186, 'hippopotamus': 0.0183}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ANNOTATIONS_FILENAME = 'annotations.csv'\n",
        "\n",
        "def create_annotations_csv_file(annotations_filename = ANNOTATIONS_FILENAME, img_dir = JPEGIMAGES_FOLDER_PATH): \n",
        "    \"\"\" \n",
        "    Create a csv annotations_file, annotations.csv, with two columns, in the format : \n",
        "                        path/to/image, label\n",
        "    \n",
        "    The annotation csv is necessary for DataLoader.\n",
        "    \"\"\"\n",
        "    \n",
        "    labels_dirs:list = os.listdir(img_dir)\n",
        "   \n",
        "    if os.path.exists(annotations_filename):\n",
        "        os.remove(annotations_filename)\n",
        "        print(f'Deleted existent {ANNOTATIONS_FILENAME} file.\\n ---------------------------')\n",
        "    \n",
        "    with open(annotations_filename, 'w', newline='') as file :\n",
        "        writer = csv.writer(file, dialect='excel', delimiter=',')\n",
        "\n",
        "        for i, label in enumerate(labels_dirs) : \n",
        "\n",
        "            specific_label_path = os.path.join(img_dir, label)\n",
        "            images_names = os.listdir(specific_label_path)\n",
        "\n",
        "            for j, image_name in enumerate(images_names):\n",
        "                full_path_to_img= os.path.join(specific_label_path, image_name)\n",
        "                full_path_to_img= os.path.join(label, image_name)\n",
        "\n",
        "                row = [full_path_to_img, label]\n",
        "                writer.writerow(row)\n",
        "\n",
        "    print(f'Sucessfully created {ANNOTATIONS_FILENAME} file.')\n",
        "\n",
        "#\n",
        "create_annotations_csv_file()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHvq8ylVsxDF",
        "outputId": "8c478685-2610-4955-9e60-36d0846fa619"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sucessfully created annotations.csv file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# labels_in_number = pd.read_csv(DATA_FOLDER_PATH+\"classes.txt\", delim_whitespace=True,header=None)\n",
        "labels_dict = {}\n",
        "with open(DATA_FOLDER_PATH+\"classes.txt\") as f:\n",
        "    for line in f:\n",
        "        # print(line.split())\n",
        "        (key,val) = line.split()\n",
        "        labels_dict[val] = int(key)-1\n",
        "print(labels_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEi7KhPbsxAO",
        "outputId": "f4bc3bce-082a-46ea-b136-3126f77a060f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'antelope': 0, 'grizzly+bear': 1, 'killer+whale': 2, 'beaver': 3, 'dalmatian': 4, 'persian+cat': 5, 'horse': 6, 'german+shepherd': 7, 'blue+whale': 8, 'siamese+cat': 9, 'skunk': 10, 'mole': 11, 'tiger': 12, 'hippopotamus': 13, 'leopard': 14, 'moose': 15, 'spider+monkey': 16, 'humpback+whale': 17, 'elephant': 18, 'gorilla': 19, 'ox': 20, 'fox': 21, 'sheep': 22, 'seal': 23, 'chimpanzee': 24, 'hamster': 25, 'squirrel': 26, 'rhinoceros': 27, 'rabbit': 28, 'bat': 29, 'giraffe': 30, 'wolf': 31, 'chihuahua': 32, 'rat': 33, 'weasel': 34, 'otter': 35, 'buffalo': 36, 'zebra': 37, 'giant+panda': 38, 'deer': 39, 'bobcat': 40, 'pig': 41, 'lion': 42, 'mouse': 43, 'polar+bear': 44, 'collie': 45, 'walrus': 46, 'raccoon': 47, 'cow': 48, 'dolphin': 49}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AWA2Dataset(Dataset): # Dataset class to serve as input for the DataLoader.\n",
        "    \"\"\" \n",
        "    Dataset class to serve as input for the DataLoader.\n",
        "    Implements all the required methods and more. \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, annotations_file=ANNOTATIONS_FILENAME, img_dir=JPEGIMAGES_FOLDER_PATH, \n",
        "                transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        numbers_infos_dicts: tuple[dict,dict] = find_num_images_per_label(img_dir=JPEGIMAGES_FOLDER_PATH)\n",
        "        self.num_images_per_label = numbers_infos_dicts[0]\n",
        "        self.proportions_images_per_label = numbers_infos_dicts[1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        # img_path = self.img_labels.iloc[idx, 0]\n",
        "        key = self.img_labels.iloc[idx, 1]\n",
        "\n",
        "        # Mapping the labels from string to tensor\n",
        "        label = labels_dict[key]\n",
        "\n",
        "        image = read_image(img_path)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "3kgEOFu4sw94"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "dataset = AWA2Dataset()\n",
        "dataset.transform=transform"
      ],
      "metadata": {
        "id": "ZFqrhoUHsw7Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers =0, shuffle=False)\n",
        "\n",
        "# GlobalSum = 0\n",
        "# num_images_processed=0\n",
        "\n",
        "# Function provided by https://www.binarystudy.com/2021/04/how-to-calculate-mean-standard-deviation-images-pytorch.html\n",
        "def batch_mean_and_sd(dataloader):\n",
        "    global GlobalSum\n",
        "    global num_images_processed\n",
        "    cnt = 0\n",
        "    fst_moment = torch.empty(3)\n",
        "    snd_moment = torch.empty(3)\n",
        "\n",
        "    for i, (images, labels) in enumerate(dataloader):\n",
        "        b, c, h, w = images.shape\n",
        "        nb_pixels = b * h * w\n",
        "        # num_images_processed += b\n",
        "        sum_ = torch.sum(images, dim=[0, 2, 3])\n",
        "        # GlobalSum +=sum_\n",
        "        sum_of_square = torch.sum(images ** 2,dim=[0, 2, 3])\n",
        "        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
        "        snd_moment = (cnt * snd_moment + sum_of_square) / (cnt + nb_pixels)\n",
        "        cnt += nb_pixels\n",
        "\n",
        "        if i % 250 == 0 :\n",
        "          print(f'processed image # {i} / {len(dataset)}')\n",
        "\n",
        "    mean, std = fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)        \n",
        "    return mean,std\n",
        "\n",
        "mean, std = batch_mean_and_sd(dataloader)\n",
        "print(\"mean and std: \\n\", mean, std) \n"
      ],
      "metadata": {
        "id": "U4DDWTqwREa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88554962-bfcd-4f46-e54d-3593cb98daa9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed image # 0 / 37340\n",
            "processed image # 250 / 37340\n",
            "processed image # 500 / 37340\n",
            "processed image # 750 / 37340\n",
            "processed image # 1000 / 37340\n",
            "processed image # 1250 / 37340\n",
            "processed image # 1500 / 37340\n",
            "processed image # 1750 / 37340\n",
            "processed image # 2000 / 37340\n",
            "processed image # 2250 / 37340\n",
            "processed image # 2500 / 37340\n",
            "processed image # 2750 / 37340\n",
            "processed image # 3000 / 37340\n",
            "processed image # 3250 / 37340\n",
            "processed image # 3500 / 37340\n",
            "processed image # 3750 / 37340\n",
            "processed image # 4000 / 37340\n",
            "processed image # 4250 / 37340\n",
            "processed image # 4500 / 37340\n",
            "processed image # 4750 / 37340\n",
            "processed image # 5000 / 37340\n",
            "processed image # 5250 / 37340\n",
            "processed image # 5500 / 37340\n",
            "processed image # 5750 / 37340\n",
            "processed image # 6000 / 37340\n",
            "processed image # 6250 / 37340\n",
            "processed image # 6500 / 37340\n",
            "processed image # 6750 / 37340\n",
            "processed image # 7000 / 37340\n",
            "processed image # 7250 / 37340\n",
            "processed image # 7500 / 37340\n",
            "processed image # 7750 / 37340\n",
            "processed image # 8000 / 37340\n",
            "processed image # 8250 / 37340\n",
            "processed image # 8500 / 37340\n",
            "processed image # 8750 / 37340\n",
            "processed image # 9000 / 37340\n",
            "processed image # 9250 / 37340\n",
            "processed image # 9500 / 37340\n",
            "processed image # 9750 / 37340\n",
            "processed image # 10000 / 37340\n",
            "processed image # 10250 / 37340\n",
            "processed image # 10500 / 37340\n",
            "processed image # 10750 / 37340\n",
            "processed image # 11000 / 37340\n",
            "processed image # 11250 / 37340\n",
            "processed image # 11500 / 37340\n",
            "processed image # 11750 / 37340\n",
            "processed image # 12000 / 37340\n",
            "processed image # 12250 / 37340\n",
            "processed image # 12500 / 37340\n",
            "processed image # 12750 / 37340\n",
            "processed image # 13000 / 37340\n",
            "processed image # 13250 / 37340\n",
            "processed image # 13500 / 37340\n",
            "processed image # 13750 / 37340\n",
            "processed image # 14000 / 37340\n",
            "processed image # 14250 / 37340\n",
            "processed image # 14500 / 37340\n",
            "processed image # 14750 / 37340\n",
            "processed image # 15000 / 37340\n",
            "processed image # 15250 / 37340\n",
            "processed image # 15500 / 37340\n",
            "processed image # 15750 / 37340\n",
            "processed image # 16000 / 37340\n",
            "processed image # 16250 / 37340\n",
            "processed image # 16500 / 37340\n",
            "processed image # 16750 / 37340\n",
            "processed image # 17000 / 37340\n",
            "processed image # 17250 / 37340\n",
            "processed image # 17500 / 37340\n",
            "processed image # 17750 / 37340\n",
            "processed image # 18000 / 37340\n",
            "processed image # 18250 / 37340\n",
            "processed image # 18500 / 37340\n",
            "processed image # 18750 / 37340\n",
            "processed image # 19000 / 37340\n",
            "processed image # 19250 / 37340\n",
            "processed image # 19500 / 37340\n",
            "processed image # 19750 / 37340\n",
            "processed image # 20000 / 37340\n",
            "processed image # 20250 / 37340\n",
            "processed image # 20500 / 37340\n",
            "processed image # 20750 / 37340\n",
            "processed image # 21000 / 37340\n",
            "processed image # 21250 / 37340\n",
            "processed image # 21500 / 37340\n",
            "processed image # 21750 / 37340\n",
            "processed image # 22000 / 37340\n",
            "processed image # 22250 / 37340\n",
            "processed image # 22500 / 37340\n",
            "processed image # 22750 / 37340\n",
            "processed image # 23000 / 37340\n",
            "processed image # 23250 / 37340\n",
            "processed image # 23500 / 37340\n",
            "processed image # 23750 / 37340\n",
            "processed image # 24000 / 37340\n",
            "processed image # 24250 / 37340\n",
            "processed image # 24500 / 37340\n",
            "processed image # 24750 / 37340\n",
            "processed image # 25000 / 37340\n",
            "processed image # 25250 / 37340\n",
            "processed image # 25500 / 37340\n",
            "processed image # 25750 / 37340\n",
            "processed image # 26000 / 37340\n",
            "processed image # 26250 / 37340\n",
            "processed image # 26500 / 37340\n",
            "processed image # 26750 / 37340\n",
            "processed image # 27000 / 37340\n",
            "processed image # 27250 / 37340\n",
            "processed image # 27500 / 37340\n",
            "processed image # 27750 / 37340\n",
            "processed image # 28000 / 37340\n",
            "processed image # 28250 / 37340\n",
            "processed image # 28500 / 37340\n",
            "processed image # 28750 / 37340\n",
            "processed image # 29000 / 37340\n",
            "processed image # 29250 / 37340\n",
            "processed image # 29500 / 37340\n",
            "processed image # 29750 / 37340\n",
            "processed image # 30000 / 37340\n",
            "processed image # 30250 / 37340\n",
            "processed image # 30500 / 37340\n",
            "processed image # 30750 / 37340\n",
            "processed image # 31000 / 37340\n",
            "processed image # 31250 / 37340\n",
            "processed image # 31500 / 37340\n",
            "processed image # 31750 / 37340\n",
            "processed image # 32000 / 37340\n",
            "processed image # 32250 / 37340\n",
            "processed image # 32500 / 37340\n",
            "processed image # 32750 / 37340\n",
            "processed image # 33000 / 37340\n",
            "processed image # 33250 / 37340\n",
            "processed image # 33500 / 37340\n",
            "processed image # 33750 / 37340\n",
            "processed image # 34000 / 37340\n",
            "processed image # 34250 / 37340\n",
            "processed image # 34500 / 37340\n",
            "processed image # 34750 / 37340\n",
            "processed image # 35000 / 37340\n",
            "processed image # 35250 / 37340\n",
            "processed image # 35500 / 37340\n",
            "processed image # 35750 / 37340\n",
            "processed image # 36000 / 37340\n",
            "processed image # 36250 / 37340\n",
            "processed image # 36500 / 37340\n",
            "processed image # 36750 / 37340\n",
            "processed image # 37000 / 37340\n",
            "processed image # 37250 / 37340\n",
            "mean and std: \n",
            " tensor([0.4643, 0.4640, 0.3985]) tensor([0.2521, 0.2425, 0.2538])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean and Std of dataset is :    \n",
        "\n",
        "# [0.4643, 0.4640, 0.3985] , [0.2521, 0.2425, 0.2538]"
      ],
      "metadata": {
        "id": "QtOn8VR3jBKZ"
      }
    }
  ]
}