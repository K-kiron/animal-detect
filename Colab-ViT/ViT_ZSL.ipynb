{"cells":[{"cell_type":"markdown","metadata":{"id":"xrm1Sci01iDL"},"source":[" # Import library"]},{"cell_type":"code","source":["pip install timm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LQrdgsSlmFr-","executionInfo":{"status":"ok","timestamp":1680026358455,"user_tz":240,"elapsed":6240,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"}},"outputId":"ddc08108-0e09-40d5-ff0f-644d0a56322c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting timm\n","  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm) (6.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from timm) (0.14.1+cu116)\n","Collecting huggingface-hub\n","  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.9/dist-packages (from timm) (1.13.1+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (4.5.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (3.10.2)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (8.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (1.22.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n","Installing collected packages: huggingface-hub, timm\n","Successfully installed huggingface-hub-0.13.3 timm-0.6.13\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4283,"status":"ok","timestamp":1680026367114,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"},"user_tz":240},"id":"dE9BtQhU1p0P"},"outputs":[],"source":["import timm\n","import numpy as np\n","import matplotlib.pyplot as plt                        \n","import torch\n","import torchvision.models as models\n","import torch.nn as nn\n","import os,sys\n","import scipy.io as sio\n","import pdb\n","from time import time\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset\n","from PIL import Image\n","from torchvision import transforms\n","from torch.utils.data import Dataset\n","import random\n","import torchvision.transforms.functional as TF\n","from tqdm.notebook import tqdm\n","from scipy import spatial\n","from scipy.special import softmax\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{"id":"GV0vVi0J2fse"},"source":["# Load Data"]},{"cell_type":"markdown","metadata":{"id":"H7_vnkmG9JZ8"},"source":["### Downloading Images \n","It is recommended to download images for the desired datasets before continue running the code\n","\n","Images can be downloaded via the following links:\n","\n","\n","**AWA2**: https://cvml.ist.ac.at/AwA2/AwA2-data.zip\n","\n","\n","**CUB**: http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz\n","\n","\n","**SUN**: http://cs.brown.edu/~gmpatter/Attributes/SUNAttributeDB_Images.tar.gz\n","\n","*Refer to the attached .txt file named as \"Dataset_Instruction\" for more information*"]},{"cell_type":"markdown","metadata":{"id":"ynSJKlAU8YK0"},"source":["### Downloading Attributes\n","For more information, refer to https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/zero-shot-learning/zero-shot-learning-the-good-the-bad-and-the-ugly \n"]},{"cell_type":"markdown","metadata":{"id":"DyXA4-t39I-D"},"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"SxYs_zC28jMi","executionInfo":{"status":"ok","timestamp":1680026424776,"user_tz":240,"elapsed":46120,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"}}},"outputs":[],"source":["%%bash\n","if [ -d \"./data\" ] \n","then\n","    echo \"Files are already there.\"\n","else\n","    wget -q \"http://datasets.d2.mpi-inf.mpg.de/xian/xlsa17.zip\"\n","    unzip -q xlsa17.zip -d ./data\n","fi"]},{"cell_type":"markdown","metadata":{"id":"HoUxvCLR4l5l"},"source":["### Choose the Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"MiXo9Mcx2s-o","executionInfo":{"status":"ok","timestamp":1680026428160,"user_tz":240,"elapsed":140,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"}}},"outputs":[],"source":["DATASET = 'AWA2' # [\"AWA2\", \"CUB\", \"SUN\"]\n"]},{"cell_type":"markdown","metadata":{"id":"6g8SBGx-4pgH"},"source":["Set Dataset Paths"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"eaHE7G_hksxO","executionInfo":{"status":"ok","timestamp":1679979798112,"user_tz":240,"elapsed":3,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"}}},"outputs":[],"source":["if DATASET == 'AWA2':\n","  ROOT='/content/drive/MyDrive/IFT3710/Animals_with_Attributes2/JPEGImages/'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19917,"status":"ok","timestamp":1679979410495,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"},"user_tz":240},"id":"wAswvHsXkxyu","outputId":"4496f15f-4d6f-4574-b379-ddf30c7a1096"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"pa4OpphZ6N_l","executionInfo":{"status":"ok","timestamp":1680026432537,"user_tz":240,"elapsed":133,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"}}},"outputs":[],"source":["if DATASET == 'AWA2':\n","  ROOT='./data/AWA2/Animals_with_Attributes2/JPEGImages/'\n","elif DATASET == 'CUB':\n","  ROOT='./data/CUB/CUB_200_2011/CUB_200_2011/images/'\n","elif DATASET == 'SUN':\n","  ROOT='./data/SUN/images/'\n","else:\n","  print(\"Please specify the dataset\")"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"UNizCSl24p8c","executionInfo":{"status":"ok","timestamp":1680026439241,"user_tz":240,"elapsed":3877,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"}}},"outputs":[],"source":["DATA_DIR = f'./data/xlsa17/data/{DATASET}'\n","data = sio.loadmat(f'{DATA_DIR}/res101.mat') \n","# data consists of files names \n","attrs_mat = sio.loadmat(f'{DATA_DIR}/att_splits.mat')\n","# attrs_mat is the attributes (class-level information)\n","image_files = data['image_files']\n","\n","if DATASET == 'AWA2':\n","  image_files = np.array([im_f[0][0].split('JPEGImages/')[-1] for im_f in image_files])\n","else:\n","  image_files = np.array([im_f[0][0].split('images/')[-1] for im_f in image_files])\n","\n","\n","# labels are indexed from 1 as it was done in Matlab, so 1 subtracted for Python\n","labels = data['labels'].squeeze().astype(np.int64) - 1\n","train_idx = attrs_mat['train_loc'].squeeze() - 1\n","val_idx = attrs_mat['val_loc'].squeeze() - 1\n","trainval_idx = attrs_mat['trainval_loc'].squeeze() - 1\n","test_seen_idx = attrs_mat['test_seen_loc'].squeeze() - 1\n","test_unseen_idx = attrs_mat['test_unseen_loc'].squeeze() - 1\n","\n","# consider the train_labels and val_labels\n","train_labels = labels[train_idx]\n","val_labels = labels[val_idx]\n","\n","# split train_idx to train_idx (used for training) and val_seen_idx\n","train_idx, val_seen_idx = train_test_split(train_idx, test_size=0.2, stratify=train_labels)\n","# split val_idx to val_idx (not useful) and val_unseen_idx\n","val_unseen_idx = train_test_split(val_idx, test_size=0.2, stratify=val_labels)[1]\n","# attribute matrix\n","attrs_mat = attrs_mat[\"att\"].astype(np.float32).T\n","\n","### used for validation\n","# train files and labels\n","train_files = image_files[train_idx]\n","train_labels = labels[train_idx]\n","uniq_train_labels, train_labels_based0, counts_train_labels = np.unique(train_labels, return_inverse=True, return_counts=True)\n","# val seen files and labels\n","val_seen_files = image_files[val_seen_idx]\n","val_seen_labels = labels[val_seen_idx]\n","uniq_val_seen_labels = np.unique(val_seen_labels)\n","# val unseen files and labels\n","val_unseen_files = image_files[val_unseen_idx]\n","val_unseen_labels = labels[val_unseen_idx]\n","uniq_val_unseen_labels = np.unique(val_unseen_labels)\n","\n","### used for testing\n","# trainval files and labels\n","trainval_files = image_files[trainval_idx]\n","trainval_labels = labels[trainval_idx]\n","uniq_trainval_labels, trainval_labels_based0, counts_trainval_labels = np.unique(trainval_labels, return_inverse=True, return_counts=True)\n","# test seen files and labels\n","test_seen_files = image_files[test_seen_idx]\n","test_seen_labels = labels[test_seen_idx]\n","uniq_test_seen_labels = np.unique(test_seen_labels)\n","# test unseen files and labels\n","test_unseen_files = image_files[test_unseen_idx]\n","test_unseen_labels = labels[test_unseen_idx]\n","uniq_test_unseen_labels = np.unique(test_unseen_labels)"]},{"cell_type":"markdown","metadata":{"id":"YvD9KYa7HFDd"},"source":["# Data Generator"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ruyuo3mOkbkc","executionInfo":{"status":"ok","timestamp":1680026444072,"user_tz":240,"elapsed":108,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"}}},"outputs":[],"source":["class DataLoader(Dataset):\n","    def __init__(self, root, image_files, labels, transform=None):\n","        self.root  = root\n","        self.image_files = image_files\n","        self.labels = labels \n","        self.transform = transform\n","\n","    def __getitem__(self, idx):\n","        # read the iterable image\n","        img_pil = Image.open(os.path.join(self.root, self.image_files[idx])).convert(\"RGB\")\n","        if self.transform is not None:\n","            img = self.transform(img_pil)\n","        # label\n","        label = self.labels[idx]\n","        return img, label\n","\n","    def __len__(self):\n","        return len(self.image_files)"]},{"cell_type":"markdown","metadata":{"id":"k2fvK83IHgc3"},"source":["# Transformations"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"38ODTaNRHtj4","executionInfo":{"status":"ok","timestamp":1680026449943,"user_tz":240,"elapsed":241,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"}}},"outputs":[],"source":["# Training Transformations\n","trainTransform = transforms.Compose([\n","                        transforms.Resize((224, 224)),\n","                        transforms.RandomHorizontalFlip(),\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.485, 0.456, 0.406), \n","                                             (0.229, 0.224, 0.225))])\n","# Testing Transformations\n","testTransform = transforms.Compose([\n","                        transforms.Resize((224, 224)),\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.485, 0.456, 0.406), \n","                                             (0.229, 0.224, 0.225))])"]},{"cell_type":"markdown","metadata":{"id":"AFCakFQZH4ew"},"source":["### Average meter"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"5Ni1zP7TH7yr","executionInfo":{"status":"ok","timestamp":1680026450285,"user_tz":240,"elapsed":3,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"}}},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"cell_type":"markdown","metadata":{"id":"M_bMTKlLIHWY"},"source":["# Train Function"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"TPCWpV0pIKVM","executionInfo":{"status":"ok","timestamp":1680026452711,"user_tz":240,"elapsed":253,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"}}},"outputs":[],"source":["def train(model, data_loader, train_attrbs, optimizer, use_cuda, lamb_1=1.0):\n","    \"\"\"returns trained model\"\"\"    \n","    # initialize variables to monitor training and validation loss\n","    loss_meter = AverageMeter()\n","    \"\"\" train the model  \"\"\"\n","    model.train()\n","    tk = tqdm(data_loader, total=int(len(data_loader)))\n","    for batch_idx, (data, label) in enumerate(tk):\n","        # move to GPU\n","        if use_cuda:\n","            data,  label = data.cuda(), label.cuda()\n","        optimizer.zero_grad()\n","        \n","        x_g = model.vit(data)[0]\n","        # global feature\n","        feat_g = model.mlp_g(x_g)\n","        logit_g = feat_g @ train_attrbs.T\n","        loss = lamb_1 * F.cross_entropy(logit_g, label)\n","        loss.backward()\n","        optimizer.step()\n","        loss_meter.update(loss.item(), label.shape[0])\n","        tk.set_postfix({\"loss\": loss_meter.avg})\n","        \n","    # print training/validation statistics \n","    print('Train: Average loss: {:.4f}\\n'.format(loss_meter.avg))\n","    \n","\n","def get_reprs(model, data_loader, use_cuda):\n","    model.eval()\n","    reprs = []\n","    for _, (data, _) in enumerate(data_loader):\n","        if use_cuda:\n","            data = data.cuda()\n","        with torch.no_grad():\n","            # only take the global feature\n","            feat = model.vit(data)[0]\n","            feat = model.mlp_g(feat)\n","        reprs.append(feat.cpu().data.numpy())\n","    reprs = np.concatenate(reprs, 0)\n","    return reprs\n","\n","def compute_accuracy(pred_labels, true_labels, labels):\n","    acc_per_class = np.zeros(labels.shape[0])\n","    for i in range(labels.shape[0]):\n","        idx = (true_labels == labels[i])\n","        acc_per_class[i] = np.sum(pred_labels[idx] == true_labels[idx]) / np.sum(idx)\n","    return np.mean(acc_per_class)\n","\n","def validation(model, seen_loader, seen_labels, unseen_loader, unseen_labels, attrs_mat, use_cuda, gamma=None):\n","    # Representation\n","    with torch.no_grad():\n","        seen_reprs = get_reprs(model, seen_loader, use_cuda)\n","        unseen_reprs = get_reprs(model, unseen_loader, use_cuda)\n","\n","    # Labels\n","    uniq_labels = np.unique(np.concatenate([seen_labels, unseen_labels]))\n","    updated_seen_labels = np.searchsorted(uniq_labels, seen_labels)\n","    uniq_updated_seen_labels = np.unique(updated_seen_labels)\n","    updated_unseen_labels = np.searchsorted(uniq_labels, unseen_labels)\n","    uniq_updated_unseen_labels = np.unique(updated_unseen_labels)\n","    uniq_updated_labels = np.unique(np.concatenate([updated_seen_labels, updated_unseen_labels]))\n","\n","    # truncate the attribute matrix\n","    trunc_attrs_mat = attrs_mat[uniq_labels]\n","  \n","    #### ZSL ####\n","    zsl_unseen_sim = unseen_reprs @ trunc_attrs_mat[uniq_updated_unseen_labels].T\n","    pred_labels = np.argmax(zsl_unseen_sim, axis=1)\n","    zsl_unseen_predict_labels = uniq_updated_unseen_labels[pred_labels]\n","    zsl_unseen_acc = compute_accuracy(zsl_unseen_predict_labels, updated_unseen_labels, uniq_updated_unseen_labels)\n","    \n","    #### GZSL ####\n","    # seen classes\n","    gzsl_seen_sim = softmax(seen_reprs @ trunc_attrs_mat.T, axis=1)\n","    # unseen classes\n","    gzsl_unseen_sim = softmax(unseen_reprs @ trunc_attrs_mat.T, axis=1)\n","\n","    gammas = np.arange(0.0, 1.1, 0.1)\n","    gamma_opt = 0\n","    H_max = 0\n","    gzsl_seen_acc_max = 0\n","    gzsl_unseen_acc_max = 0\n","    # Calibrated stacking\n","    for igamma in range(gammas.shape[0]):\n","        # Calibrated stacking\n","        gamma = gammas[igamma]\n","        gamma_mat = np.zeros(trunc_attrs_mat.shape[0])\n","        gamma_mat[uniq_updated_seen_labels] = gamma\n","\n","        gzsl_seen_pred_labels = np.argmax(gzsl_seen_sim - gamma_mat, axis=1)\n","        # gzsl_seen_predict_labels = uniq_updated_labels[pred_seen_labels]\n","        gzsl_seen_acc = compute_accuracy(gzsl_seen_pred_labels, updated_seen_labels, uniq_updated_seen_labels)\n","\n","        gzsl_unseen_pred_labels = np.argmax(gzsl_unseen_sim - gamma_mat, axis=1)\n","        # gzsl_unseen_predict_labels = uniq_updated_labels[pred_unseen_labels]\n","        gzsl_unseen_acc = compute_accuracy(gzsl_unseen_pred_labels, updated_unseen_labels, uniq_updated_unseen_labels)\n","\n","        H = 2 * gzsl_seen_acc * gzsl_unseen_acc / (gzsl_seen_acc + gzsl_unseen_acc)\n","\n","        if H > H_max:\n","            gzsl_seen_acc_max = gzsl_seen_acc\n","            gzsl_unseen_acc_max = gzsl_unseen_acc\n","            H_max = H\n","            gamma_opt = gamma\n","\n","    print('ZSL: averaged per-class accuracy: {0:.2f}'.format(zsl_unseen_acc * 100))\n","    print('GZSL Seen: averaged per-class accuracy: {0:.2f}'.format(gzsl_seen_acc_max * 100))\n","    print('GZSL Unseen: averaged per-class accuracy: {0:.2f}'.format(gzsl_unseen_acc_max * 100))\n","    print('GZSL: harmonic mean (H): {0:.2f}'.format(H_max * 100))\n","    print('GZSL: gamma: {0:.2f}'.format(gamma_opt))\n","\n","    return gamma_opt\n","\n","\n","def test(model, test_seen_loader, test_seen_labels, test_unseen_loader, test_unseen_labels, attrs_mat, use_cuda, gamma):\n","    # Representation\n","    with torch.no_grad():\n","        seen_reprs = get_reprs(model, test_seen_loader, use_cuda)\n","        unseen_reprs = get_reprs(model, test_unseen_loader, use_cuda)\n","    # Labels\n","    uniq_test_seen_labels = np.unique(test_seen_labels)\n","    uniq_test_unseen_labels = np.unique(test_unseen_labels)\n","\n","    # ZSL\n","    zsl_unseen_sim = unseen_reprs @ attrs_mat[uniq_test_unseen_labels].T\n","    predict_labels = np.argmax(zsl_unseen_sim, axis=1)\n","    zsl_unseen_predict_labels = uniq_test_unseen_labels[predict_labels]\n","    zsl_unseen_acc = compute_accuracy(zsl_unseen_predict_labels, test_unseen_labels, uniq_test_unseen_labels)\n","\n","    # Calibrated stacking\n","    Cs_mat = np.zeros(attrs_mat.shape[0])\n","    Cs_mat[uniq_test_seen_labels] = gamma\n","\n","    # GZSL\n","    # seen classes\n","    gzsl_seen_sim = softmax(seen_reprs @ attrs_mat.T, axis=1) - Cs_mat\n","    gzsl_seen_predict_labels = np.argmax(gzsl_seen_sim, axis=1)\n","    gzsl_seen_acc = compute_accuracy(gzsl_seen_predict_labels, test_seen_labels, uniq_test_seen_labels)\n","    \n","    # unseen classes\n","    gzsl_unseen_sim = softmax(unseen_reprs @ attrs_mat.T, axis=1) - Cs_mat\n","    gzsl_unseen_predict_labels = np.argmax(gzsl_unseen_sim, axis=1)\n","    gzsl_unseen_acc = compute_accuracy(gzsl_unseen_predict_labels, test_unseen_labels, uniq_test_unseen_labels)\n","\n","    H = 2 * gzsl_unseen_acc * gzsl_seen_acc / (gzsl_unseen_acc + gzsl_seen_acc)\n","\n","    print('ZSL: averaged per-class accuracy: {0:.2f}'.format(zsl_unseen_acc * 100))\n","    print('GZSL Seen: averaged per-class accuracy: {0:.2f}'.format(gzsl_seen_acc * 100))\n","    print('GZSL Unseen: averaged per-class accuracy: {0:.2f}'.format(gzsl_unseen_acc * 100))\n","    print('GZSL: harmonic mean (H): {0:.2f}'.format(H * 100))\n","    print('GZSL: gamma: {0:.2f}'.format(gamma))"]},{"cell_type":"markdown","metadata":{"id":"U6Ch_i62IxQT"},"source":["# Data Loaders"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"dH61DOxDkbke","executionInfo":{"status":"ok","timestamp":1680026455791,"user_tz":240,"elapsed":130,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"}}},"outputs":[],"source":["num_workers = 4\n","### used in validation\n","# train data loader\n","train_data = DataLoader(ROOT, train_files, train_labels_based0, transform=trainTransform)\n","weights_ = 1. / counts_train_labels\n","weights = weights_[train_labels_based0]\n","train_sampler = torch.utils.data.WeightedRandomSampler(weights, num_samples=train_labels_based0.shape[0], replacement=True)\n","train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=32, sampler=train_sampler, num_workers=num_workers)\n","# seen val data loader\n","val_seen_data = DataLoader(ROOT, val_seen_files, val_seen_labels, transform=testTransform)\n","val_seen_data_loader = torch.utils.data.DataLoader(val_seen_data, batch_size=256, shuffle=False, num_workers=num_workers)\n","# unseen val data loader\n","val_unseen_data = DataLoader(ROOT, val_unseen_files, val_unseen_labels, transform=testTransform)\n","val_unseen_data_loader = torch.utils.data.DataLoader(val_unseen_data, batch_size=256, shuffle=False, num_workers=num_workers)\n","\n","### used in testing\n","# trainval data loader\n","trainval_data = DataLoader(ROOT, trainval_files, trainval_labels_based0, transform=trainTransform)\n","weights_ = 1. / counts_trainval_labels\n","weights = weights_[trainval_labels_based0]\n","trainval_sampler = torch.utils.data.WeightedRandomSampler(weights, num_samples=trainval_labels_based0.shape[0], replacement=True)\n","trainval_data_loader = torch.utils.data.DataLoader(trainval_data, batch_size=32, sampler=trainval_sampler, num_workers=num_workers)\n","# seen test data loader\n","test_seen_data = DataLoader(ROOT, test_seen_files, test_seen_labels, transform=testTransform)\n","test_seen_data_loader = torch.utils.data.DataLoader(test_seen_data, batch_size=256, shuffle=False, num_workers=num_workers)\n","# unseen test data loader\n","test_unseen_data = DataLoader(ROOT, test_unseen_files, test_unseen_labels, transform=testTransform)\n","test_unseen_data_loader = torch.utils.data.DataLoader(test_unseen_data, batch_size=256, shuffle=False, num_workers=num_workers)"]},{"cell_type":"markdown","metadata":{"id":"8F2lgZOAI24k"},"source":["# Baseline Model (ViT)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"3W08lH9FI8O-","executionInfo":{"status":"ok","timestamp":1680026458496,"user_tz":240,"elapsed":449,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"}}},"outputs":[],"source":["class ViT(nn.Module):\n","    def __init__(self, model_name=\"vit_large_patch16_224_in21k\", pretrained=True):\n","        super(ViT, self).__init__()\n","        self.vit = timm.create_model(model_name, pretrained=pretrained)\n","        # Others variants of ViT can be used as well\n","        '''\n","        1 --- 'vit_small_patch16_224'\n","        2 --- 'vit_base_patch16_224'\n","        3 --- 'vit_large_patch16_224',\n","        4 --- 'vit_large_patch32_224'\n","        5 --- 'vit_deit_base_patch16_224'\n","        6 --- 'deit_base_distilled_patch16_224',\n","        '''\n","\n","        # Change the head depending of the dataset used \n","        self.vit.head = nn.Identity()\n","    def forward(self, x):\n","        x = self.vit.patch_embed(x)\n","        cls_token = self.vit.cls_token.expand(x.shape[0], -1, -1)  \n","        if self.vit.dist_token is None:\n","            x = torch.cat((cls_token, x), dim=1)\n","        else:\n","            x = torch.cat((cls_token, self.vit.dist_token.expand(x.shape[0], -1, -1), x), dim=1)\n","        x = self.vit.pos_drop(x + self.vit.pos_embed)\n","        x = self.vit.blocks(x)\n","        x = self.vit.norm(x)\n","        \n","        return x[:, 0], x[:, 1:]"]},{"cell_type":"markdown","metadata":{"id":"oB0jr5sMJLdv"},"source":["# Model and Optimizer Initialization"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"V1lLFB0qJNqH","executionInfo":{"status":"ok","timestamp":1680026519340,"user_tz":240,"elapsed":57565,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"}}},"outputs":[],"source":["import collections\n","from torch import optim\n","use_cuda = torch.cuda.is_available()\n","\n","if DATASET == 'AWA2':\n","  attr_length = 85\n","elif DATASET == 'CUB':\n","  attr_length = 312\n","elif DATASET == 'SUN':\n","  attr_length = 102\n","else:\n","  print(\"Please specify the dataset, and set {attr_length} equal to the attribute length\")\n","\n","vit = ViT(\"vit_large_patch16_224_in21k\")\n","mlp_g = nn.Linear(1024, attr_length, bias=False)\n","\n","model = nn.ModuleDict({\n","    \"vit\": vit,\n","    \"mlp_g\": mlp_g})\n","\n","# finetune all the parameters\n","for param in model.parameters():\n","    param.requires_grad = True\n","    \n","# move model to GPU if CUDA is available\n","if use_cuda:\n","    model = model.cuda()\n","\n","optimizer = torch.optim.Adam([{\"params\": model.vit.parameters(), \"lr\": 0.00001, \"weight_decay\": 0.0001},\n","                              {\"params\": model.mlp_g.parameters(), \"lr\": 0.001, \"weight_decay\": 0.00001}])\n","                              \n","lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20, 30, 40], gamma=0.5)\n","#lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.1)\n","\n","\n","# train attributes\n","train_attrbs = attrs_mat[uniq_train_labels]\n","train_attrbs_tensor = torch.from_numpy(train_attrbs)\n","# trainval attributes\n","trainval_attrbs = attrs_mat[uniq_trainval_labels]\n","trainval_attrbs_tensor = torch.from_numpy(trainval_attrbs)\n","if use_cuda:\n","    train_attrbs_tensor = train_attrbs_tensor.cuda()\n","    trainval_attrbs_tensor = trainval_attrbs_tensor.cuda()"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"2RX6Adhhkbkf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680026519341,"user_tz":240,"elapsed":25,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"}},"outputId":"312c72bd-b975-436f-cbcc-7ac0b25d9016"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["ModuleDict(\n","  (vit): ViT(\n","    (vit): VisionTransformer(\n","      (patch_embed): PatchEmbed(\n","        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n","        (norm): Identity()\n","      )\n","      (pos_drop): Dropout(p=0.0, inplace=False)\n","      (norm_pre): Identity()\n","      (blocks): Sequential(\n","        (0): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (1): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (2): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (3): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (4): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (5): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (6): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (7): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (8): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (9): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (10): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (11): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (12): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (13): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (14): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (15): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (16): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (17): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (18): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (19): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (20): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (21): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (22): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","        (23): Block(\n","          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (attn): Attention(\n","            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","            (attn_drop): Dropout(p=0.0, inplace=False)\n","            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (proj_drop): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls1): Identity()\n","          (drop_path1): Identity()\n","          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","            (act): GELU(approximate='none')\n","            (drop1): Dropout(p=0.0, inplace=False)\n","            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","            (drop2): Dropout(p=0.0, inplace=False)\n","          )\n","          (ls2): Identity()\n","          (drop_path2): Identity()\n","        )\n","      )\n","      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","      (fc_norm): Identity()\n","      (head): Identity()\n","    )\n","  )\n","  (mlp_g): Linear(in_features=1024, out_features=85, bias=False)\n",")"]},"metadata":{},"execution_count":14}],"source":["model"]},{"cell_type":"markdown","metadata":{"id":"0YznkklMKV25"},"source":["# Training and Testing the model"]},{"cell_type":"markdown","metadata":{"id":"pPCFuP9dK3wn"},"source":["### Setting the calibration factor"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"1mPTYAvVKXf9","colab":{"base_uri":"https://localhost:8080/","height":635,"referenced_widgets":["7de7e069da674c78a309c11e4031f513","d9a65b7b1a934a38b68a0a3f1220e694","b9bfa5591bda402a96dabc97ece6f89f","97bf3035a3874532aee01fb9fa8bfcd1","d601949c5b0444c1b5a1199564306a7d","fb611c96c5fa4d88bb65bf1f49b61bee","44d8c7540e51450e87a2d3848f1b45bb","a8ac0e565a1649c692175b343652c928","13f935f70b264c76989aca0e60be2868","8ed531454e0e422bb04a030f32b8dc76","a9bbf10dd1634524bee6fc81caed7521"]},"executionInfo":{"status":"error","timestamp":1680026956011,"user_tz":240,"elapsed":259,"user":{"displayName":"Mila Quebec","userId":"10679210924075687823"}},"outputId":"b68abb38-24ed-4fa4-a02f-d2686b538ddb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/405 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7de7e069da674c78a309c11e4031f513"}},"metadata":{}},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-714db2485082>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgammas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_attrbs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_seen_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_seen_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_unseen_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_unseen_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-7f2117f1ff50>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, train_attrbs, optimizer, use_cuda, lamb_1)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# move to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-7-1063f61d2ac2>\", line 10, in __getitem__\n    img_pil = Image.open(os.path.join(self.root, self.image_files[idx])).convert(\"RGB\")\n  File \"/usr/local/lib/python3.9/dist-packages/PIL/Image.py\", line 2975, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: './data/AWA2/Animals_with_Attributes2/JPEGImages/tiger/tiger_10823.jpg'\n"]}],"source":["\"\"\" Only Run this cell if you are to tune the calibration factor (gamma)\n","    It is data-dependent, and decided based on the validation set \"\"\"\n","gammas = []\n","for i in range(20):\n","    train(model, train_data_loader, train_attrbs_tensor, optimizer, use_cuda, lamb_1=1.0)\n","    lr_scheduler.step()\n","    gamma = validation(model, val_seen_data_loader, val_seen_labels, val_unseen_data_loader, val_unseen_labels, attrs_mat, use_cuda)\n","    gammas.append(gamma)\n","gamma = np.mean(gammas)\n","print(gamma)"]},{"cell_type":"markdown","metadata":{"id":"s8lAQPtcLttQ"},"source":["### Calibration factor is Set\n","It is 0.9 for AWA2 and CUB\n","0.4 for SUN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Q8fdI_8L9pN"},"outputs":[],"source":["if DATASET == 'AWA2':\n","  gamma = 0.9\n","elif DATASET == 'CUB':\n","  gamma = 0.9\n","elif DATASET == 'SUN':\n","  gamma = 0.4\n","else:\n","  print(\"Please specify the dataset, and set {attr_length} equal to the attribute length\")\n","print('Dataset:', DATASET, '\\nGamma:',gamma)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kURToL76kbkg","scrolled":false},"outputs":[],"source":["for i in range(80):\n","    train(model, trainval_data_loader, trainval_attrbs_tensor, optimizer, use_cuda, lamb_1=1.0)\n","    print(' .... Saving model ...')\n","    print('Epoch: ', i)\n","    save_path= str(DATASET) + '__ViT-ZSL__' +'Epoch_' + str(i) + '.pt'\n","    ckpt_path = './checkpoint/' + str(DATASET)\n","    path = os.path.join(ckpt_path, save_path)\n","    torch.save(model.state_dict(), path)\n","\n","    lr_scheduler.step()\n","    test(model, test_seen_data_loader, test_seen_labels, test_unseen_data_loader, test_unseen_labels, attrs_mat, use_cuda, gamma)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6lJcbOsIkbkg"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["Nr2V4fFG5MSw","ynSJKlAU8YK0","aceqa0YpGrpj","YvD9KYa7HFDd","AFCakFQZH4ew","M_bMTKlLIHWY","8F2lgZOAI24k"],"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7de7e069da674c78a309c11e4031f513":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d9a65b7b1a934a38b68a0a3f1220e694","IPY_MODEL_b9bfa5591bda402a96dabc97ece6f89f","IPY_MODEL_97bf3035a3874532aee01fb9fa8bfcd1"],"layout":"IPY_MODEL_d601949c5b0444c1b5a1199564306a7d"}},"d9a65b7b1a934a38b68a0a3f1220e694":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb611c96c5fa4d88bb65bf1f49b61bee","placeholder":"​","style":"IPY_MODEL_44d8c7540e51450e87a2d3848f1b45bb","value":"  0%"}},"b9bfa5591bda402a96dabc97ece6f89f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8ac0e565a1649c692175b343652c928","max":405,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13f935f70b264c76989aca0e60be2868","value":0}},"97bf3035a3874532aee01fb9fa8bfcd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ed531454e0e422bb04a030f32b8dc76","placeholder":"​","style":"IPY_MODEL_a9bbf10dd1634524bee6fc81caed7521","value":" 0/405 [00:00&lt;?, ?it/s]"}},"d601949c5b0444c1b5a1199564306a7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb611c96c5fa4d88bb65bf1f49b61bee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44d8c7540e51450e87a2d3848f1b45bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8ac0e565a1649c692175b343652c928":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13f935f70b264c76989aca0e60be2868":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ed531454e0e422bb04a030f32b8dc76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9bbf10dd1634524bee6fc81caed7521":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}